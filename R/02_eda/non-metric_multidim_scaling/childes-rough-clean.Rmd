---
title: "CHILDES Subset - Rough Clean"
subtitle: "Non-Metric Multidimensional Scaling"
author: "Grace Lawley"
date: "5/16/2018"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setup
```{r setting up, message=FALSE, warning=FALSE}
## Loading packages ===========================================================
library(here)
library(readr)
library(dplyr)
library(stringr)
library(tidyr)
library(MASS)
library(knitr)
library(ggplot2)
library(ggrepel)
library(corrplot)


## CHILDES corpus types =======================================================

# Input path ------------------------------------------------------------------
file_in_path = here('data/processed/')
# -----------------------------------------------------------------------------


# List of all corpora used
corpora <- c('bloom1970', 'braunwald', 'brown', 'clark', 
             'cornell', 'demetras-trevor', 'ellisweismer',
             'hall', 'kuczaj', 'macwhinney', 'sachs', 'suppes',
             'warren', 'weist')

# Creating lists of file names/paths for corpora
file_names <- paste0(corpora, '_type-count.csv')
file_paths <- paste0(file_in_path, file_names)

# Importing and combining individual corpora type counts
file_data <- lapply(file_paths, read_csv)
corpora_type_count <- bind_rows(file_data)



## Overall types ==============================================================

# Input path ------------------------------------------------------------------
types_in_path = here("data/processed/all_overall_types.csv")
# -----------------------------------------------------------------------------

# Importing csv of all types
all_types <- read_csv(types_in_path)
```


# Frequency Lists
## Calculating Frequencies
Frequency by corpora, *n*
```{r frequency lists}
## Creating a tidy frequency list =============================================
freq_list_tidy <- data.frame(unique(corpora_type_count[, 1:3])) %>% 
  group_by(db_version, collection, corpus) %>% 
  expand(word = all_types$word) %>%  # adding column of overall types
  left_join(corpora_type_count,  
            by = c('db_version', 'collection',
                   'corpus', 'word')) %>%  # adding in corpora type counts
  ungroup(freq_list) %>%
  rename(freq = n) %>% 
  replace_na(list(freq = 0))
  

## Creating an untidy frequency list ==========================================
freq_raw <- freq_list_tidy %>% 
  dplyr::select(word, corpus, freq) %>% 
  spread(key = corpus, value = freq)
```
## Transforming Frequencies
$$log_{10}(n+1)$$  
```{r transform freq}
## Transforming frequencies in tidy version ===================================
freq_list_tidy <- freq_list_tidy %>% 
  mutate(log10_freq_plus1 = log10(freq + 1))

## Creating an untidy transformed frequency list ==============================
freq_trans <- freq_list_tidy %>% 
  dplyr::select(word, corpus, log10_freq_plus1) %>% 
  spread(key = corpus, value = log10_freq_plus1)
```


# Cleaning
## Counts & Proportions
```{r cleaning 1, echo = FALSE}
freq_raw <- freq_raw %>% 
  mutate(N = rowSums(freq_raw[, -1]))

freq_raw %>% 
  group_by(N) %>% 
  summarize(count = n(), 
            prop = count/nrow(freq_raw)) %>% 
  head(n = 10) %>% 
  kable(caption = 'Types by Overall Frequency Count, N')
```

## Creating Subsets
For four scenarios:

1. Including only types of N > 1  
2. Including only types of N > 2  
3. Including only types of N > 3  
4. Including only types of N > 4  
```{r cleaning 2}
# Removing types with N <= 1 --------------------------------------------------
freq_1 <- freq_raw %>% 
  filter(N > 1)

freq_1_trans <- freq_1[, -16]
freq_1_trans[, -1] <- log10(freq_1_trans[, -1] + 1)
  

# Removing types with N <= 2 --------------------------------------------------
freq_2 <- freq_raw %>% 
  filter(N > 2) 

freq_2_trans <- freq_2 [, -16]
freq_2_trans[, -1] <- log10(freq_2_trans[, -1] + 1)


# Removing types with N <= 3 --------------------------------------------------
freq_3 <- freq_raw %>% 
  filter(N > 3)

freq_3_trans <- freq_3[, -16]
freq_3_trans[, -1] <- log10(freq_3_trans[, -1] + 1)


# Removing types with N <= 4 --------------------------------------------------
freq_4 <- freq_raw %>% 
  filter(N > 4)

freq_4_trans <- freq_4[, -16]
freq_4_trans[, -1] <- log10(freq_4_trans[, -1] + 1)
```


# Correlation Matrices
Using the transformed frequency counts, $log_{10}(n+1)$  

## Calculating  
```{r correlation matrice}
M_1 <- freq_1_trans %>% 
  dplyr::select(-word) %>% 
  cor()

M_2 <- freq_2_trans %>% 
  dplyr::select(-word) %>% 
  cor()

M_3 <- freq_3_trans %>% 
  dplyr::select(-word) %>% 
  cor()

M_4 <- freq_4_trans %>% 
  dplyr::select(-word) %>% 
  cor()
```
## Visualizations {.tabset}
### N > 1  
```{r corr visualization 1, fig.height = 8, fig.width = 8, echo = FALSE}
corrplot(round(M_1, 2), method = 'number', tl.srt = 45, mar = c(0, 0, 2, 0),
         title = 'Including only types of N > 1')
```

### N > 2  
```{r corr visualization 2, fig.height = 8, fig.width = 8, echo = FALSE}
corrplot(round(M_2, 2), method = 'number', tl.srt = 45, mar = c(0, 0, 2, 0),
         title = 'Including only types of N > 2')
```

### N > 3  
```{r corr visualization 3, fig.height = 8, fig.width = 8, echo = FALSE}
corrplot(round(M_3, 2), method = 'number', tl.srt = 45, mar = c(0, 0, 2, 0),
         title = 'Including only types of N > 3')
```

### N > 4  
```{r corr visualization 4, fig.height = 8, fig.width = 8, echo = FALSE}
corrplot(round(M_4, 2), method = 'number', tl.srt = 45, mar = c(0, 0, 2, 0),
         title = 'Including only types of N > 4')
```



# Non-Metric Multidimensional Scaling
Using the transformed frequency counts, $log_{10}(n+1)$  

## Calculating {.tabset}
### N > 1
```{r nm-mds 1, echo = FALSE}
nm_mds_1 <- isoMDS(d = 1 - M_1, k = 2)
```

### N > 2
```{r nm-mds 2, echo = FALSE}
nm_mds_2 <- isoMDS(d = 1 - M_2, k = 2)
```

### N > 3
```{r nm-mds 3, echo = FALSE}
nm_mds_3 <- isoMDS(d = 1 - M_3, k = 2)
```

### N > 4
```{r nm-mds 4, echo = FALSE}
nm_mds_4 <- isoMDS(d = 1 - M_4, k = 2)
```

## Visualizations {.tabset}
### N > 1  
```{r nm-mds vis 1, echo = FALSE}
nm_mds_1$points %>% 
  as.data.frame %>% 
  rename(x = V1, y = V2) %>% 
  ggplot(aes(x, y, label = rownames(nm_mds_1$points))) +
    geom_point(color = 'red') +
    geom_text_repel(size = 3.5) +
    theme_minimal() +
    labs(title = 'CHILDES Subset, only types of n > 1', subtitle = 'Non-Metric Multidimensional Scaling', 
         caption = paste0('Stress = ',  round(nm_mds_1$stress, 4)))
```

### N > 2  
```{r nm-mds vis 2, echo = FALSE}
nm_mds_2$points %>% 
  as.data.frame %>% 
  rename(x = V1, y = V2) %>% 
  ggplot(aes(x, y, label = rownames(nm_mds_2$points))) +
    geom_point(color = 'blue') +
    geom_text_repel(size = 3.5) +
    theme_minimal() +
    labs(title = 'CHILDES Subset, only types of n > 2', subtitle = 'Non-Metric Multidimensional Scaling', 
         caption = paste0('Stress = ',  round(nm_mds_2$stress, 4)))
```

### N > 3  
```{r nm-mds vis 3, echo = FALSE}
nm_mds_3$points %>% 
  as.data.frame %>% 
  rename(x = V1, y = V2) %>% 
  ggplot(aes(x, y, label = rownames(nm_mds_3$points))) +
    geom_point(color = 'green') +
    geom_text_repel(size = 3.5) +
    theme_minimal() +
    labs(title = 'CHILDES Subset, only types of n > 3', subtitle = 'Non-Metric Multidimensional Scaling', 
         caption = paste0('Stress = ',  round(nm_mds_3$stress, 4)))
```

### N > 4  
```{r nm-mds vis 4, echo = FALSE}
nm_mds_4$points %>% 
  as.data.frame %>% 
  rename(x = V1, y = V2) %>% 
  ggplot(aes(x, y, label = rownames(nm_mds_4$points))) +
    geom_point(color = 'yellow') +
    geom_text_repel(size = 3.5) +
    theme_minimal() +
    labs(title = 'CHILDES Subset, only types of n > 4', subtitle = 'Non-Metric Multidimensional Scaling', 
         caption = paste0('Stress = ',  round(nm_mds_4$stress, 4)))
```
