---
title: "CHILDES - Non-Metric Multidimensional Scaling"
author: "Grace Lawley"
date: "5/16/2018"
output:
  html_document:
    code_folding: show
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 0. Loading packages
```{r load packages, message=FALSE, warning=FALSE}
library(here)
library(readr)
library(dplyr)
library(stringr)
library(tidyr)
library(MASS)
library(knitr)
library(ggplot2)
library(ggrepel)
library(corrplot)
```

### 1. Importing individual type-count data for each of the 14 corpora and combining into dataframe: `corpora_type_count`
```{r import and gather corpora type counts, message=FALSE}

## Input path ------------------------------------------------------
file_in_path = here('data/processed/')
## -----------------------------------------------------------------


# List of all corpora used
corpora <- c('bloom1970', 'braunwald', 'brown', 'clark', 
             'cornell', 'demetras-trevor', 'ellisweismer',
             'hall', 'kuczaj', 'macwhinney', 'sachs', 'suppes',
             'warren', 'weist')

# Creating lists of file names/paths for corpora
file_names <- paste0(corpora, '_type-count.csv')
file_paths <- paste0(file_in_path, file_names)

# Importing and combining individual corpora type counts
file_data <- lapply(file_paths, read_csv)
corpora_type_count <- bind_rows(file_data)

corpora_type_count
```


### 2. Importing csv file with the 'global types' (types of the union of the 14 corpora) and saving as dataframe: `all_types`
```{r importing all types, message=FALSE}

## Input path ------------------------------------------------------
types_in_path = here("data/processed/all_types.csv")
## -----------------------------------------------------------------

# Importing csv of all types
all_types <- read_csv(types_in_path)

all_types
```

### 3. Creating a frequency list for rate of occurence of all 'global types' in each of the 14 corpora and saving as dataframe: `freq_list`
```{r creating frequency list}

# Creating the frequency list
freq_list <- data.frame(unique(corpora_type_count[, 1:3])) %>% 
  group_by(db_version, collection, corpus) %>% 
  
  # Adding in column of all types
  expand(word = all_types$word) %>% 
  
  # Adding in type counts 
  left_join(corpora_type_count,
            by = c('db_version', 'collection',
                   'corpus', 'word')) %>% 
  
  # Ungrouping freq_list
  ungroup(freq_list) %>% 
  
  # Renaming n to freq
  rename(freq = n) %>% 
  
  # Changing unseen types from NA to 0
  replace_na(list(freq = 0))

freq_list
```


__Number of types with frequency of 0 = __ `r sum(freq_list$freq == 0)`

__Proportion of types with frequency of 0 = __ `r sum(freq_list$freq == 0)/nrow(freq_list)`



### 4. Transforming frequencies: `freq` to `log10(freq+1)`
```{r transform freq}
freq_list <- freq_list %>% 
  mutate(log10_freq_plus_1 = log10(freq+1))

freq_list
```

### 5. Creating correlation matrix, `M`
```{r correlation matrix}

# Changing freq_list into layout required by cor()
freq_list_cor <- freq_list %>% 
  dplyr::select(word, corpus, log10_freq_plus_1) %>% 
  spread(key = corpus, value = log10_freq_plus_1) 


# Creating correlation matrix
M  <- freq_list_cor %>% 
  dplyr::select(-word) %>% 
  cor()
```

```{r corrplot, fig.height=8, fig.width=8}
corrplot(round(M, 4), method="number")
```

### 6. Non-Metric Multi-Dimensional Scaling
```{r nm-mds calc}
nm_mds <- isoMDS(d = 1-M, k = 2)
nm_mds
```

```{r nm-mds visualization}
df_nm_mds <- as.data.frame(nm_mds$points) %>% 
  rename(x = V1, y = V2)

ggplot(df_nm_mds, aes(x, y, label = rownames(df_nm_mds))) +
  geom_label() +
  theme_minimal()
```


```{r}
ggplot(df_nm_mds, aes(x, y, label = rownames(df_nm_mds))) +
  geom_point(color = 'red') +
  geom_text_repel(size = 3.5) +
  theme_minimal()
```


