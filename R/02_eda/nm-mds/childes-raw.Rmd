---
title: "CHILDES Subset Raw"
subtitle: "Non-Metric Multidimensional Scaling"
author: "Grace Lawley"
date: "5/16/2018"
output:
  html_document:
    number_sections: true
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Setup
```{r setting up, message=FALSE, warning=FALSE}
## Loading packages ===========================================================
library(here)
library(readr)
library(dplyr)
library(stringr)
library(tidyr)
library(MASS)
library(knitr)
library(ggplot2)
library(ggrepel)
library(corrplot)


## CHILDES corpus types =======================================================

# Input path ------------------------------------------------------------------
file_in_path = here('data/processed/')
# -----------------------------------------------------------------------------


# List of all corpora used
corpora <- c('bloom1970', 'braunwald', 'brown', 'clark', 
             'cornell', 'demetras-trevor', 'ellisweismer',
             'hall', 'kuczaj', 'macwhinney', 'sachs', 'suppes',
             'warren', 'weist')

# Creating lists of file names/paths for corpora
file_names <- paste0(corpora, '_type-count.csv')
file_paths <- paste0(file_in_path, file_names)

# Importing and combining individual corpora type counts
file_data <- lapply(file_paths, read_csv)
corpora_type_count <- bind_rows(file_data)



## Overall types ==============================================================

# Input path ------------------------------------------------------------------
types_in_path = here("data/processed/all_overall_types.csv")
# -----------------------------------------------------------------------------

# Importing csv of all types
all_types <- read_csv(types_in_path)
```

# Frequency Lists
## Calculating Frequencies
Frequency by corpora, *n*
```{r frequency lists}
## Creating a tidy frequency list =============================================
freq_list_tidy <- data.frame(unique(corpora_type_count[, 1:3])) %>% 
  group_by(db_version, collection, corpus) %>% 
  expand(word = all_types$word) %>%  # adding column of overall types
  left_join(corpora_type_count,  
            by = c('db_version', 'collection',
                   'corpus', 'word')) %>%  # adding in corpora type counts
  ungroup(freq_list) %>%
  rename(freq = n) %>% 
  replace_na(list(freq = 0))
  

## Creating an untidy frequency list ==========================================
freq_raw <- freq_list_tidy %>% 
  dplyr::select(word, corpus, freq) %>% 
  spread(key = corpus, value = freq)
```
## Transforming Frequencies
$$log_{10}(n+1)$$  
```{r freq transform}
## Transforming frequencies in tidy version ===================================
freq_list_tidy <- freq_list_tidy %>% 
  mutate(log10_freq_plus1 = log10(freq + 1))

## Creating an untidy transformed frequency list ==============================
freq_trans <- freq_list_tidy %>% 
  dplyr::select(word, corpus, log10_freq_plus1) %>% 
  spread(key = corpus, value = log10_freq_plus1)
```


# Correlation Matrices
Using the transformed frequency counts, $log_{10}(n+1)$  

## Calculating  
```{r correlation calc}
M <- freq_trans %>% 
  dplyr::select(-word) %>% 
  cor()
```

## Visualization
```{r corr visualization, fig.height = 8, fig.width = 8, echo = FALSE}
corrplot(round(M, 2), method = 'number', tl.srt = 45)
```

# Non-Metric Multidimensional Scaling:
Using the transformed frequency counts, $log_{10}(n+1)$  

## Calculating  
```{r nm-mds}
nm_mds <- isoMDS(d = 1 - M, k = 2)
```
## Visualization
```{r nm-mds visualization, echo = FALSE}
nm_mds$points %>% 
  as.data.frame %>% 
  rename(x = V1, y = V2) %>% 
  ggplot(aes(x, y, label = rownames(nm_mds$points))) +
    geom_point(color = 'red') +
    geom_text_repel(size = 3.5) +
    theme_minimal() +
    labs(title = 'CHILDES Subset Raw', subtitle = 'Non-Metric Multidimensional Scaling', 
         caption = paste0('Stress = ',  round(nm_mds$stress, 4)))
```







